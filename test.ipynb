{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "571afb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70207cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    loaded_model = load_model('asl_model.keras')\n",
    "except:\n",
    "    # Fallback if custom objects aren't registered\n",
    "    loaded_model = load_model('asl_model.keras', compile=False)\n",
    "    loaded_model.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# 2. Load the label encoder\n",
    "with open('label_encoder.pkl', 'rb') as f:\n",
    "    loaded_le = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca243f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Summary ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_27          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_28          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,188</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_27          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_28          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │         \u001b[38;5;34m1,188\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,484</span> (80.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,484\u001b[0m (80.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> (78.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,100\u001b[0m (78.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Now verify both are loaded correctly\n",
    "print(\"=== Model Summary ===\")\n",
    "loaded_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42611ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Available ASL Classes ===\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Available ASL Classes ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[43mloaded_le\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m))\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'classes_'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n=== Available ASL Classes ===\")\n",
    "print(list(loaded_le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59df3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loaded from numpy array ===\n",
      "Total classes: 36\n",
      "Class labels: ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h'\n",
      " 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
      "\n",
      "Test Prediction:\n",
      "Top: 0 (70.5%)\n",
      "Top 3:\n",
      "- 0: 70.5%\n",
      "- q: 9.0%\n",
      "- o: 6.5%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "\n",
    "# 1. Register the custom loss function (if needed)\n",
    "@register_keras_serializable()\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fn(y_true, y_pred):\n",
    "        import tensorflow as tf\n",
    "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        return -tf.reduce_mean(alpha * tf.pow(1. - pt, gamma) * tf.math.log(pt + 1e-8))\n",
    "    return focal_loss_fn\n",
    "\n",
    "# 2. Load model with custom objects\n",
    "try:\n",
    "    loaded_model = load_model('asl_model.keras', \n",
    "                            custom_objects={'focal_loss_fn': focal_loss()})\n",
    "except Exception as e:\n",
    "    print(f\"Error loading with custom loss: {e}\\nLoading without compilation...\")\n",
    "    loaded_model = load_model('asl_model.keras', compile=False)\n",
    "    loaded_model.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# 3. Load and verify labels (handling numpy array case)\n",
    "with open('label_encoder.pkl', 'rb') as f:\n",
    "    label_data = pickle.load(f)\n",
    "    \n",
    "if isinstance(label_data, np.ndarray):\n",
    "    class_labels = label_data\n",
    "    print(\"\\n=== Loaded from numpy array ===\")\n",
    "else:  # Assume it's a LabelEncoder\n",
    "    class_labels = label_data.classes_\n",
    "    print(\"\\n=== Loaded from LabelEncoder ===\")\n",
    "\n",
    "print(f\"Total classes: {len(class_labels)}\")\n",
    "print(\"Class labels:\", class_labels)\n",
    "\n",
    "# 4. Prediction function\n",
    "def predict_asl_sign(landmarks):\n",
    "    \"\"\"Enhanced prediction with error handling\"\"\"\n",
    "    try:\n",
    "        landmarks = np.array(landmarks).reshape(1, -1).astype('float32')\n",
    "        if landmarks.shape[1] != 63:\n",
    "            raise ValueError(f\"Expected 63 landmarks, got {landmarks.shape[1]}\")\n",
    "            \n",
    "        preds = loaded_model.predict(landmarks, verbose=0)[0]\n",
    "        sorted_preds = sorted(zip(class_labels, preds), \n",
    "                            key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return {\n",
    "            'top': sorted_preds[0],\n",
    "            'top_3': sorted_preds[:3],\n",
    "            'all': sorted_preds,\n",
    "            'is_digit': sorted_preds[0][0] in '0123456789'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test prediction\n",
    "sample = np.random.rand(63).tolist()  # Replace with real data\n",
    "result = predict_asl_sign(sample)\n",
    "\n",
    "if result:\n",
    "    print(\"\\nTest Prediction:\")\n",
    "    print(f\"Top: {result['top'][0]} ({result['top'][1]:.1%})\")\n",
    "    print(\"Top 3:\")\n",
    "    for char, prob in result['top_3']:\n",
    "        print(f\"- {char}: {prob:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf8f0c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Predicted: 0 (70.5% confidence)\n",
      "\n",
      "Top alternatives:\n",
      "1. Q (9.0%)\n",
      "2. O (6.5%)\n",
      "Visual similarity warning: 0 ↔ O\n",
      "Visual similarity warning: 0 ↔ Q\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Add these right after your existing prediction code\n",
    "\n",
    "MIN_CONFIDENCE = 0.7\n",
    "CONFUSION_PAIRS = {\n",
    "    '0': ['o', 'q'],\n",
    "    '1': ['l'],\n",
    "    '5': ['s'],\n",
    "    '6': ['b'],\n",
    "    '9': ['g']\n",
    "}\n",
    "\n",
    "def check_confusions(prediction):\n",
    "    char, _ = prediction['top']\n",
    "    for similar in CONFUSION_PAIRS.get(char, []):\n",
    "        if similar in [x[0] for x in prediction['top_3']]:\n",
    "            print(f\"Visual similarity warning: {char.upper()} ↔ {similar.upper()}\")\n",
    "\n",
    "def display_prediction(result):\n",
    "    if not result:\n",
    "        print(\"No prediction available\")\n",
    "        return\n",
    "    \n",
    "    char, confidence = result['top']\n",
    "    char = char.upper()  # Convert to uppercase\n",
    "    \n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Predicted: {char} ({confidence:.1%} confidence)\")\n",
    "    \n",
    "    if confidence < MIN_CONFIDENCE:\n",
    "        print(\"⚠️ Low confidence warning\")\n",
    "    \n",
    "    print(\"\\nTop alternatives:\")\n",
    "    for i, (alt_char, alt_prob) in enumerate(result['top_3'][1:], 1):\n",
    "        print(f\"{i}. {alt_char.upper()} ({alt_prob:.1%})\")\n",
    "    \n",
    "    check_confusions(result)\n",
    "    print('='*40)\n",
    "\n",
    "# Test it\n",
    "display_prediction(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
